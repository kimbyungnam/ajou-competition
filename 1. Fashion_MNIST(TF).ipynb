{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget --no-check-certificate -P ./ -N https://s3.ap-northeast-2.amazonaws.com/mjgim/fmnist_test.csv\n",
    "! wget --no-check-certificate -P ./ -N https://s3.ap-northeast-2.amazonaws.com/mjgim/fmnist_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.loadtxt(\"fmnist_train.csv\", delimiter=\",\")\n",
    "training_img = training_data[:,1:]\n",
    "training_lab = training_data[:,0]\n",
    "\n",
    "test_img = np.loadtxt(\"fmnist_test.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set (images) shape: {shape}\".format(shape=training_img.shape))\n",
    "print(\"Training set (labels) shape: {shape}\".format(shape=training_lab.shape))\n",
    "\n",
    "print(\"Test set (images) shape: {shape}\".format(shape=test_img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 20\n",
    "\n",
    "idx_s = np.random.randint(0,len(training_img), sample_size)\n",
    "fig, ax = plt.subplots(1, sample_size, figsize=(sample_size*2, 2))\n",
    "\n",
    "for i in range(sample_size):\n",
    "    ax[i].set_axis_off()\n",
    "    ax[i].imshow(np.reshape(training_img[idx_s][i], [28,28]),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making fileque\n",
    "def group_list(l, group_size):\n",
    "\n",
    "    for i in range(0, len(l), group_size):\n",
    "        yield l[i:i+group_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden layer 구성\n",
    "- CNN layer\n",
    "```p\n",
    "tf.layers.conv2d(inputs=, filters=, kernel_size=, padding=, activation=)\n",
    "tf.layers.max_pooling2d(inputs=, pool_size=, padding=, strides=)\n",
    "```\n",
    "- Dropout\n",
    "```p\n",
    "tf.nn.dropout(x, keep_prob)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set parameter\n",
    "\n",
    "learning_rate = \n",
    "batch_size = \n",
    "n_epoch = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.int32, [None])\n",
    "Y_ = tf.one_hot(Y, depth=10,  dtype=tf.float32)\n",
    "\n",
    "\n",
    "H = tf.layers.dense(X , 10, activation=tf.nn.softmax)\n",
    "\n",
    "loss = - tf.reduce_mean(tf.reduce_sum(Y_ * tf.log(H), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer 변경\n",
    "- GradientDescentOptimizer\n",
    "- MomentumOptimizer\n",
    "- RMSPropOptimizer\n",
    "- AdamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(H,1), tf.argmax(Y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "cost_list = []\n",
    "acc_list = []\n",
    "\n",
    "for i in range(n_epoch):\n",
    "    cost = 0.\n",
    "    x_batch = group_list(training_img, batch_size)\n",
    "    y_batch = group_list(training_lab, batch_size)\n",
    "\n",
    "    for j in range(len(training_img)//batch_size):\n",
    "        batch_xs = next(x_batch)\n",
    "        batch_ys = next(y_batch)\n",
    "        _, c = sess.run([train, loss], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        cost += c/(len(training_img)//batch_size)\n",
    "    cost_list.append(cost)\n",
    "\n",
    "    acc = sess.run(accuracy, feed_dict={X: training_img, Y: training_lab})\n",
    "    acc_list.append(acc)\n",
    "    \n",
    "    \n",
    "result = sess.run(tf.argmax(H,1), feed_dict={X: test_img})\n",
    "np.savetxt(\"fmnist_result.csv\", result, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.subplot(221)\n",
    "plt.title(\"Cost of Trining data\")\n",
    "plt.xlabel(\"Steps\")\n",
    "_ = plt.plot(cost_list, \"c\", label=\"Cost\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.title(\"Accuracy of Training data\")\n",
    "plt.xlabel(\"Steps\")\n",
    "_ = plt.plot(acc_list, \"k--\", label=\"Accuracy\")\n",
    "plt.legend()\n",
    "print(\"Accuracy of Training data : %0.5f\" %acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
